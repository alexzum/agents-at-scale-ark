apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  name: evaluator-context-enhanced
  labels:
    evaluated: "true"
spec:
  description: Test enhanced evaluator with context precision and recall support
  steps:
  - name: setup-environment
    try:
    - script:
        skipLogOutput: true
        content: |
          set -u
          echo "{\"token\": \"$E2E_TEST_AZURE_OPENAI_KEY\", \"url\": \"$E2E_TEST_AZURE_OPENAI_BASE_URL\"}"
        outputs:
        - name: azure
          value: (json_parse($stdout))
    - apply:
        file: manifests/a00-rbac.yaml
    - apply:
        file: manifests/a01-configmap.yaml
    - apply:
        file: manifests/a02-secret.yaml
    - apply:
        file: manifests/a03-model.yaml
    - apply:
        file: manifests/a04-evaluator.yaml
    - apply:
        file: manifests/a05-agent.yaml
    - apply:
        file: manifests/a06-query.yaml

  - name: wait-for-resources
    try:
    - assert:
        resource:
          apiVersion: ark.mckinsey.com/v1alpha1
          kind: Model
          metadata:
            name: context-enhanced-evaluation-model
          status:
            phase: ready
    - assert:
        resource:
          apiVersion: ark.mckinsey.com/v1alpha1
          kind: Evaluator
          metadata:
            name: context-enhanced-evaluator
          status:
            phase: ready
    - assert:
        resource:
          apiVersion: ark.mckinsey.com/v1alpha1
          kind: Agent
          metadata:
            name: context-test-agent

  - name: verify-evaluator-service-readiness
    try:
    - script:
        content: |
          echo "=== Verifying Evaluator Service Readiness ==="
          kubectl get pods -l app=ark-evaluator -n default
          kubectl wait --for=condition=ready pod -l app=ark-evaluator -n default --timeout=180s

          # Test service endpoint health
          kubectl run test-evaluator-health --image=curlimages/curl --rm -i --restart=Never -- \
            curl -f -s --max-time 10 "http://ark-evaluator.default.svc.cluster.local:8000/health" || \
            echo "Health check failed but continuing..."

          echo "✓ Evaluator service verification complete"

  - name: wait-for-query-completion
    try:
    - wait:
        apiVersion: ark.mckinsey.com/v1alpha1
        kind: Query
        timeout: 5m
        name: context-enhanced-query
        for:
          jsonPath:
            path: '{.status.phase}'
            value: 'done'

  - name: create-evaluation-after-query-done
    try:
    - apply:
        file: manifests/a07-evaluation.yaml
    - script:
        content: |
          echo "=== Evaluation Creation Status ==="
          kubectl get evaluation test-context-enhanced-evaluation -o yaml
          kubectl get pods -l app=ark-evaluator -n default
          kubectl logs deployment/ark-evaluator -n default --tail=20 || echo "No evaluator logs available"
          echo "=== Waiting for evaluation processing ==="

  - name: wait-for-evaluation-completion
    try:
    - wait:
        apiVersion: ark.mckinsey.com/v1alpha1
        kind: Evaluation
        timeout: 10m
        name: test-context-enhanced-evaluation
        for:
          jsonPath:
            path: '{.status.phase}'
            value: 'done'

  - name: validate-evaluation-results
    try:
    - assert:
        resource:
          apiVersion: ark.mckinsey.com/v1alpha1
          kind: Evaluation
          metadata:
            name: test-context-enhanced-evaluation
          status:
            phase: done
            (type(score) == 'string'): true
            (to_number(score) >= `0.0` && to_number(score) <= `1.0`): true
            (type(passed) == 'boolean'): true

  - name: validate-context-metadata
    try:
    - assert:
        resource:
          apiVersion: ark.mckinsey.com/v1alpha1
          kind: Evaluation
          metadata:
            name: test-context-enhanced-evaluation
            # Verify context-related metadata exists
            (contains(keys(annotations), 'evaluation.metadata/reasoning')): true
            (contains(keys(annotations), 'evaluation.metadata/criteria_scores')): true
            (contains(keys(annotations), 'evaluation.metadata/evaluation_scope')): true
            annotations:
              # Verify scope includes context criteria
              (contains(@."evaluation.metadata/evaluation_scope", 'context_precision')): true
              (contains(@."evaluation.metadata/evaluation_scope", 'context_recall')): true

  - name: validate-criteria-scores
    try:
    - script:
        content: |
          CRITERIA_SCORES=$(kubectl -n $NAMESPACE get evaluation test-context-enhanced-evaluation -o jsonpath='{.metadata.annotations.evaluation\.metadata/criteria_scores}')

          echo "=== Criteria Scores ==="
          echo "$CRITERIA_SCORES"
          echo "====================="

          # Validate context criteria are included in scoring
          if echo "$CRITERIA_SCORES" | grep -q "context_precision="; then
            echo "✓ Context precision scoring found"
          else
            echo "✗ Context precision scoring missing"
            exit 1
          fi

          if echo "$CRITERIA_SCORES" | grep -q "context_recall="; then
            echo "✓ Context recall scoring found"
          else
            echo "✗ Context recall scoring missing"
            exit 1
          fi

          echo "✓ All context-enhanced criteria validated"
        env:
        - name: NAMESPACE
          value: ($namespace)

    catch:
    - events: {}
    - describe:
        apiVersion: ark.mckinsey.com/v1alpha1
        kind: Evaluation
        name: test-context-enhanced-evaluation