apiVersion: ark.mckinsey.com/v1alpha1
kind: Model
metadata:
  name: smollm2-135m-local
  namespace: default
  annotations:
    # Pricing information in USD per million tokens
    pricing.ark.mckinsey.com/input-cost: "0.000"     # Free for local Ollama deployment
    pricing.ark.mckinsey.com/output-cost: "0.000"    # Free for local Ollama deployment
    pricing.ark.mckinsey.com/currency: "USD"
    pricing.ark.mckinsey.com/unit: "per-million-tokens"

    # Model characteristics for cost optimization
    model.ark.mckinsey.com/parameters: "135M"
    model.ark.mckinsey.com/context-window: "2048"
    model.ark.mckinsey.com/deployment-type: "local"
    model.ark.mckinsey.com/provider: "ollama"

    # Performance metrics for SLA planning
    performance.ark.mckinsey.com/avg-tokens-per-second: "120"
    performance.ark.mckinsey.com/memory-usage: "0.8GB"
    performance.ark.mckinsey.com/cpu-cores: "2"

    # Operational metadata
    ops.ark.mckinsey.com/last-updated: "2025-09-18"
    ops.ark.mckinsey.com/cost-tier: "free"
    ops.ark.mckinsey.com/recommended-use: "development,testing,analysis"
spec:
  config:
    openai:
      apiKey:
        value: not-used
      baseUrl:
        value: http://host.docker.internal:11434/v1
  model:
    value: smollm2:135m
  type: openai